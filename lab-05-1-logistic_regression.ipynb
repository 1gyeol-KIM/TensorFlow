{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 05 Logistic Classification(Regression)\n",
    "* Logistic Classfication은 True or False와 같은 Binary나 복수개의 다항 분류에 쓰입니다 (Bernoulli Distribution)\n",
    "\n",
    "### 기본 Library 선언 및 Tensorflow 버전 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 강의에 설명할 Data입니다\n",
    "* x_data가 2차원 배열이기에 2차원 공간에 표현하여 x1과 x2를 기준으로 y_data 0과 1로 구분하는 예제입니다\n",
    "* Logistic Classification 통해 보라색과 노란색 y_data(Label)을 구분해 보겠습니다.\n",
    "* Test 데이터는 붉은색의 위치와 같이 추론시 1의 값을 가지게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train = np.array([[1, 2],\n",
    "          [2, 3],\n",
    "          [3, 1],\n",
    "          [4, 3],\n",
    "          [5, 3],\n",
    "          [6, 2]])\n",
    "y_train = np.array([[0],\n",
    "          [0],\n",
    "          [0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [1]])\n",
    "\n",
    "x_test = np.array([[5,2]])\n",
    "y_test =  np.array([[1]])\n",
    "\n",
    "\n",
    "x1 = [x[0] for x in x_train]\n",
    "x2 = [x[1] for x in x_train]\n",
    "\n",
    "colors = [int(y[0] % 3) for y in y_train]\n",
    "plt.scatter(x1,x2, c=colors)\n",
    "plt.scatter(x_test[0][0],x_test[0][1], c=\"red\")\n",
    "\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Tensorflow Session\n",
    "### 위 Data를 기준으로 가설의 검증을 통해 Logistic Classification 모델을 만들도록 하겠습니다\n",
    "* Tensorflow data API를 통해 학습시킬 값들을 담는다 (Batch Size는 한번에 학습시킬 Size로 정한다)\n",
    "* features,labels는 실재 학습에 쓰일 Data (연산을 위해 Type를 맞춰준다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(x_train.shape[0]).repeat()\n",
    "\n",
    "iter = dataset.make_initializable_iterator()\n",
    "features, labels = iter.get_next()\n",
    "\n",
    "features = tf.cast(features, tf.float32)\n",
    "labels = tf.cast(labels, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위 Data를 기준으로 가설의 검증을 통해 Logistic Classification 모델을 만들도록 하겠습니다\n",
    "* W와 b은 학습을 통해 생성되는 모델에 쓰이는 Wegith와 Bias (초기값을 variable : 0이나 Random값으로 가능 tf.random_normal([2, 1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([2,1]), name='weight')\n",
    "b = tf.Variable(tf.zeros([1]), name='bias')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid 함수를 가설로 선언합니다\n",
    "* Sigmoid는 아래 그래프와 같이 0과 1의 값만을 리턴합니다 tf.sigmoid(tf.matmul(X, W) + b)와 같습니다\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "sigmoid(x) & = \\frac{1}{1+e^{-x}}  \\\\\\\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "![sigmoid](https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis  = tf.div(1., 1. + tf.exp(tf.matmul(features, W) + b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가설을 검증할 Cost 함수를 정의합니다\n",
    "$$\n",
    "\\begin{align}\n",
    "cost(h(x),y) & = −log(h(x))  &  if  &  y=1 \\\\\\\\\\\n",
    "cost(h(x),y) & = -log(1−h(x))  &  if  &  y=0\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 위 두수식을 합치면 아래과 같습니다\n",
    "$$\n",
    "\\begin{align}\n",
    "cost(h(x),y) & = −y log(h(x))−(1−y)log(1−h(x))\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = -tf.reduce_mean(labels * tf.log(hypothesis) + (1 - labels) * tf.log(1 - hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추론한 값은 0.5를 기준(Sigmoid 그래프 참조)로 0과 1의 값을 리턴합니다.\n",
    "* Sigmoid 함수를 통해 예측값이 0.5보다 크면 1을 반환하고 0.5보다 작으면 0으로 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가설을 통해 실재 값과 비교한 정확도를 측정합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.int32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow를 통한 실행을 위해 Session를 선언합니다.\n",
    "* 위의 Data를 Cost함수를 통해 학습시킨 후 모델을 생성합니다. \n",
    "* 새로운 Data를 통한 검증 수행 [5,2]의 Data로 테스트 수행 (그래프상 1이 나와야 정상입니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Loss: 0.6931\n",
      "Iter: 1000, Loss: 0.4145\n",
      "Iter: 2000, Loss: 0.3496\n",
      "Iter: 3000, Loss: 0.3014\n",
      "Iter: 4000, Loss: 0.2636\n",
      "Iter: 5000, Loss: 0.2336\n",
      "Iter: 6000, Loss: 0.2094\n",
      "Iter: 7000, Loss: 0.1896\n",
      "Iter: 8000, Loss: 0.1731\n",
      "Iter: 9000, Loss: 0.1592\n",
      "Iter: 10000, Loss: 0.1474\n",
      "\n",
      "Hypothesis:  [[0.02987642]\n",
      " [0.1576593 ]\n",
      " [0.30070737]\n",
      " [0.78328896]\n",
      " [0.9407705 ]\n",
      " [0.98057085]] \n",
      "Correct (Y):  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy:  1\n",
      "[5,2] :  [[1.]]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10001\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(EPOCHS):\n",
    "        sess.run(iter.initializer)\n",
    "        _, loss_value = sess.run([train, cost])\n",
    "        if step % 1000 == 0:\n",
    "            print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_value))\n",
    "        h, c, a = sess.run([hypothesis, predicted, accuracy])\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect (Y): \", c, \"\\nAccuracy: \", a)\n",
    "    print(\"[5,2] : \",   sess.run(predicted, feed_dict={features: x_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
