{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 12-5 sequence to sequence (Keras + eager version)\n",
    "\n",
    "### simple neural machine translation training\n",
    "\n",
    "* sequence to sequence\n",
    "  \n",
    "### Reference\n",
    "* [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnxXKDjq3jEL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# Import TensorFlow >= 1.10 and enable eager execution\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "from matplotlib import font_manager, rc\n",
    "\n",
    "rc('font', family='AppleGothic') #for mac\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [['I', 'feel', 'hungry'],\n",
    "     ['tensorflow', 'is', 'very', 'difficult'],\n",
    "     ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
    "     ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
    "targets = [['나는', '배가', '고프다'],\n",
    "           ['텐서플로우는', '매우', '어렵다'],\n",
    "           ['텐서플로우는', '딥러닝을', '위한', '프레임워크이다'],\n",
    "           ['텐서플로우는', '매우', '빠르게', '변화한다']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0,\n",
      " 'I': 1,\n",
      " 'a': 2,\n",
      " 'changing': 3,\n",
      " 'deep': 4,\n",
      " 'difficult': 5,\n",
      " 'fast': 6,\n",
      " 'feel': 7,\n",
      " 'for': 8,\n",
      " 'framework': 9,\n",
      " 'hungry': 10,\n",
      " 'is': 11,\n",
      " 'learning': 12,\n",
      " 'tensorflow': 13,\n",
      " 'very': 14}\n"
     ]
    }
   ],
   "source": [
    "# vocabulary for sources\n",
    "s_vocab = list(set(sum(sources, [])))\n",
    "s_vocab.sort()\n",
    "s_vocab = ['<pad>'] + s_vocab\n",
    "source2idx = {word : idx for idx, word in enumerate(s_vocab)}\n",
    "idx2source = {idx : word for idx, word in enumerate(s_vocab)}\n",
    "\n",
    "pprint(source2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<bos>': 1,\n",
      " '<eos>': 2,\n",
      " '<pad>': 0,\n",
      " '고프다': 3,\n",
      " '나는': 4,\n",
      " '딥러닝을': 5,\n",
      " '매우': 6,\n",
      " '배가': 7,\n",
      " '변화한다': 8,\n",
      " '빠르게': 9,\n",
      " '어렵다': 10,\n",
      " '위한': 11,\n",
      " '텐서플로우는': 12,\n",
      " '프레임워크이다': 13}\n"
     ]
    }
   ],
   "source": [
    "# vocabulary for targets\n",
    "t_vocab = list(set(sum(targets, [])))\n",
    "t_vocab.sort()\n",
    "t_vocab = ['<pad>', '<bos>', '<eos>'] + t_vocab\n",
    "target2idx = {word : idx for idx, word in enumerate(t_vocab)}\n",
    "idx2target = {idx : word for idx, word in enumerate(t_vocab)}\n",
    "\n",
    "pprint(target2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sequences, max_len, dic, mode = 'source'):\n",
    "    assert mode in ['source', 'target'], 'source와 target 중에 선택해주세요.'\n",
    "    \n",
    "    if mode == 'source':\n",
    "        # preprocessing for source (encoder)\n",
    "        s_input = list(map(lambda sentence : [dic.get(token) for token in sentence], sequences))\n",
    "        s_len = list(map(lambda sentence : len(sentence), s_input))\n",
    "        s_input = pad_sequences(sequences = s_input, maxlen = max_len, padding = 'post', truncating = 'post')\n",
    "        return s_len, s_input\n",
    "    \n",
    "    elif mode == 'target':\n",
    "        # preprocessing for target (decoder)\n",
    "        # input\n",
    "        t_input = list(map(lambda sentence : ['<bos>'] + sentence, sequences))\n",
    "        t_input = list(map(lambda sentence : [dic.get(token) for token in sentence], t_input))\n",
    "        t_len = list(map(lambda sentence : len(sentence), t_input))\n",
    "        t_input = pad_sequences(sequences = t_input, maxlen = max_len, padding = 'post', truncating = 'post')\n",
    "        \n",
    "        # output\n",
    "        t_output = list(map(lambda sentence : sentence + ['<eos>'], sequences))\n",
    "        t_output = list(map(lambda sentence : [dic.get(token) for token in sentence], t_output))\n",
    "        t_output = pad_sequences(sequences = t_output, maxlen = max_len, padding = 'post', truncating = 'post')\n",
    "        \n",
    "        return t_len, t_input, t_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 7, 5] [[ 1  7 10  0  0  0  0  0  0  0]\n",
      " [13 11 14  5  0  0  0  0  0  0]\n",
      " [13 11  2  9  8  4 12  0  0  0]\n",
      " [13 11 14  6  3  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing for source\n",
    "s_max_len = 10\n",
    "s_len, s_input = preprocess(sequences = sources,\n",
    "                            max_len = s_max_len, dic = source2idx, mode = 'source')\n",
    "print(s_len, s_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 4, 5, 5] [[ 1  4  7  3  0  0  0  0  0  0  0  0]\n",
      " [ 1 12  6 10  0  0  0  0  0  0  0  0]\n",
      " [ 1 12  5 11 13  0  0  0  0  0  0  0]\n",
      " [ 1 12  6  9  8  0  0  0  0  0  0  0]] [[ 4  7  3  2  0  0  0  0  0  0  0  0]\n",
      " [12  6 10  2  0  0  0  0  0  0  0  0]\n",
      " [12  5 11 13  2  0  0  0  0  0  0  0]\n",
      " [12  6  9  8  2  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing for target\n",
    "t_max_len = 12\n",
    "t_len, t_input, t_output = preprocess(sequences = targets,\n",
    "                                      max_len = t_max_len, dic = target2idx, mode = 'target')\n",
    "print(t_len, t_input, t_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyper-param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "epochs = 100\n",
    "batch_size = 4\n",
    "learning_rate = .005\n",
    "total_step = epochs / batch_size\n",
    "buffer_size = 100\n",
    "n_batch = buffer_size//batch_size\n",
    "embedding_dim = 32\n",
    "units = 128\n",
    "\n",
    "# input\n",
    "data = tf.data.Dataset.from_tensor_slices((s_len, s_input, t_len, t_input, t_output))\n",
    "data = data.shuffle(buffer_size = buffer_size)\n",
    "data = data.batch(batch_size = batch_size)\n",
    "# s_mb_len, s_mb_input, t_mb_len, t_mb_input, t_mb_output = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru(units):\n",
    "  # If you have a GPU, we recommend using CuDNNGRU(provides a 3x speedup than GRU)\n",
    "  # the code automatically does that.\n",
    "    if tf.test.is_gpu_available():\n",
    "        return tf.keras.layers.CuDNNGRU(units, \n",
    "                                        return_sequences=True, \n",
    "                                        return_state=True, \n",
    "                                        recurrent_initializer='glorot_uniform')\n",
    "    else:\n",
    "        return tf.keras.layers.GRU(units, \n",
    "                                   return_sequences=True, \n",
    "                                   return_state=True, \n",
    "                                   recurrent_activation='sigmoid', \n",
    "                                   recurrent_initializer='glorot_uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.enc_units)\n",
    "        \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "#         print(\"state: {}\".format(state.shape))\n",
    "#         print(\"output: {}\".format(state.shape))\n",
    "              \n",
    "        return output, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.dec_units)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "                \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        \n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        \n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "                \n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "            \n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        # * `embedding output` = The input to the decoder X is passed through an embedding layer.\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        # * `merged vector = concat(embedding output, context vector)`\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        \n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "        \n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        \n",
    "        # output shape == (batch_size * 1, vocab)\n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state\n",
    "        \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.dec_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(len(source2idx), embedding_dim, units, batch_size)\n",
    "decoder = Decoder(len(target2idx), embedding_dim, units, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer()\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = 1 - np.equal(real, 0)\n",
    "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
    "    \n",
    "#     print(\"real: {}\".format(real))\n",
    "#     print(\"pred: {}\".format(pred))\n",
    "#     print(\"mask: {}\".format(mask))\n",
    "#     print(\"loss: {}\".format(tf.reduce_mean(loss_)))\n",
    "    \n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying exponential decay learning rate to train dnn model\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "exp_decayed_lr = tf.train.exponential_decay(learning_rate=learning_rate,\n",
    "                                            global_step=global_step,\n",
    "                                            decay_steps=total_step * 5,\n",
    "                                            decay_rate=.9,\n",
    "                                            staircase=True)\n",
    "\n",
    "# creating optimizer\n",
    "opt = tf.train.AdamOptimizer(learning_rate=exp_decayed_lr)\n",
    "\n",
    "# creating check point (Object-based saving)\n",
    "checkpoint_dir = './data_out/training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                encoder=encoder,\n",
    "                                decoder=decoder)\n",
    "\n",
    "# create writer for tensorboard\n",
    "summary_writer = tf.contrib.summary.create_file_writer(logdir=checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 0.0307 Batch Loss 0.7687\n",
      "Epoch 10 Loss 0.0297 Batch Loss 0.7414\n",
      "Epoch 20 Loss 0.0267 Batch Loss 0.6676\n",
      "Epoch 30 Loss 0.0237 Batch Loss 0.5925\n",
      "Epoch 40 Loss 0.0159 Batch Loss 0.3964\n",
      "Epoch 50 Loss 0.0131 Batch Loss 0.3271\n",
      "Epoch 60 Loss 0.0100 Batch Loss 0.2498\n",
      "Epoch 70 Loss 0.0075 Batch Loss 0.1874\n",
      "Epoch 80 Loss 0.0051 Batch Loss 0.1283\n",
      "Epoch 90 Loss 0.0031 Batch Loss 0.0763\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, (s_len, s_input, t_len, t_input, t_output) in enumerate(data):\n",
    "        loss = 0\n",
    "        with tf.GradientTape() as tape:\n",
    "            enc_output, enc_hidden = encoder(s_input, hidden)\n",
    "            \n",
    "            dec_hidden = enc_hidden\n",
    "            \n",
    "            dec_input = tf.expand_dims([target2idx['<bos>']] * batch_size, 1)\n",
    "            \n",
    "            #Teacher Forcing: feeding the target as the next input\n",
    "            for t in range(1, t_input.shape[1]):\n",
    "#                 predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "                \n",
    "                loss += loss_function(t_input[:, t], predictions)\n",
    "            \n",
    "                dec_input = tf.expand_dims(t_input[:, t], 1) #using teacher forcing\n",
    "                \n",
    "        batch_loss = (loss / int(t_input.shape[1]))\n",
    "        \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        variables = encoder.variables + decoder.variables\n",
    "        \n",
    "        gradient = tape.gradient(loss, variables)\n",
    "        \n",
    "        optimizer.apply_gradients(zip(gradient, variables))\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        #save model every 10 epoch\n",
    "        print('Epoch {} Loss {:.4f} Batch Loss {:.4f}'.format(epoch,\n",
    "                                            total_loss / n_batch,\n",
    "                                            batch_loss.numpy()))\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    \n",
    "#     sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [inp_lang[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    \n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang['<bos>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "        \n",
    "        # storing the attention weigths to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += idx2target[predicted_id] + ' '\n",
    "\n",
    "        if idx2target.get(predicted_id) == '<eos>':\n",
    "            return result, sentence, attention_plot\n",
    "        \n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot\n",
    "\n",
    "# result, sentence, attention_plot = evaluate(sentence, encoder, decoder, source2idx, target2idx,\n",
    "#                                             s_max_len, t_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    \n",
    "    fontdict = {'fontsize': 14}\n",
    "    \n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
    "    result, sentence, attention_plot = evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)\n",
    "        \n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    \n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x11c4ece10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#restore checkpoint\n",
    "\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: I feel hungry\n",
      "Predicted translation: 나는 배가 고프다 고프다 고프다 고프다 고프다 고프다 고프다 고프다 고프다 고프다 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMoAAAJjCAYAAABN6Y6nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAGUxJREFUeJzt3X+MpPV92PH3Z3/dAecD7BiDk9QJYCAOYLBONEBoaHGTJqUSVBalNk1qq6FxpRY3oi0ogshNa+KqKmoVt5jKbt2Q0h+Uglopsh0bJ1B0QldKTHEPYYoNhRSH8sPmDri9nU//eJ6Fubndnc/O7swzu7xf0ordZ57nme+Jee93nnlmno3MRNLaZroegLQVGIpUYChSgaFIBYYiFRiKVGAoUoGhSAWGIhUYiqZORDwaEb8WEe/veizLDEXT6FPAKcDXIuLhiPh7EfHjXQ4ofK+XpllE7AGuaL8OAv8O+I+Z+cxEx2Eo2goi4seAvw98DPge8C3gb2bmtyZx/z710tSKiF0R8YmI+AbwNeBJ4NTMPAX4PPCfJzYWZxRNm4j4c8AvAT8LfBn4IvC17HuwRsQO4PnMPGEiYzIUTZuIeBj4AvBvM/OlVdaZB34oM/9oImMyFE2biPgE8KXMXOp6LMsMRVMnIr6fmbu7Hkc/D+Y1jf5bRFzb9SD6OaNo6kTELwOfBfbRHMz/cf/tmflvJj4mQ9G0iYh/tcbNmZmfmNhgWoaiqRMRJ61x84HMPDCxwbQMRVMnIr4NrPXeru8BtwH/YFKvjHkwr2l0N/DFzJzNzFngHcDlwO8DHwJ+Afgw8GuTGpAziqZORDwFfGjwZGNEfAj4rcy8KCJOBX43M8+cyJgMRdMmIn5Ac9b9jYHlc8ArmXnc8nqZ+Y5JjMmnXppGDwJ/fYXlf4nmXcNExAeB70xqQM4omjoRcRrwe8D/aP+7CFwC/Bzw59vlXwV+JzO/MJExGYqmUUQcA/wycBGwQBPH5zLzxYg4AfhAZj44sfEYiqZR++7gnwSOes9XZv7BpMczN+k71Hi1Z7VLv/26OMNdERHnAP8VeBF4eeDmBP7MpMdkKNvPN7oewCb4LeAzmfn5rgeyzKde21z7kuqVwPsz8zMRcSLwFyd1EDyKiHgJeFdm9roeyzJfHt7GIuIDwLeBvw3cCNCexPupiPilLsc2xJPAT3Q9iH6Gsr19HvjNzLwIONy3/Baaa2dNq18FvhARZ3U9kGU+9drG2jPcx2dmLyJezMx3tssD+P6kzmqvV0TcDZwN/BjwOEd/HsWDeW2q54H30zzYom/5B4FnOxlRzT/tegCDDGV7+yfA3RHxcdqXjCPiJ2gu//OPuhzYED8z5Pbfn8go+hjKNpaZ/7w9w/1VYFdEPA/sAH49M7/Y7ejWFAM/vwv4eWAe+IeTH47HKG8L7cXizml/fHTwXblbQUQsAF8C/jAzf3Pi928o21tE/Bzwt4Afz8wPtOdRvgT81cx8sdvRrU9EvBvYl5nvm/R9+/LwNhYRv0Lzkdl7gffCm+dR/gvw6x0ObVRvALu6uGNnlG0sIr4D/EJmfmvg5eFjgScy84c7HeAqVrm4xEk0xycHMvOjEx6SB/Pb3LuA/7XC8mSFd+VOkf/L0W/sfJlmJrxu8sPxqdd29xBwTft9/ytJVwEPTH44ZacA9wA/oBl3ACcCv0jzjuKJc0bZ3j4F3BcRFwKzEfHzwJ+m+WM8H+50ZGv7FzRx/DQDZ+W74jHKNhMRVwL3ZGZGxF8G9tK8IfKidpUHgVsy86muxjhMRLwI/GgXF7pbjaFsMxHx8vIf15nGq8JXRMQTwE9n5vNdj2WZT722n6cj4jPAfmA+In5xtRW7uNh10c3Av4yIj2bmq10PBgxlqCHXwT1CZn5vnGMpuhr4FZpjkZn2vytJYGpCWeEjzB8AvhMRDzBwAO9FuqdQRPRo/gcOvv9oULaX/5waEbE/M6fmMx1rWc8HyTLzS+Mcy0oMRSrwPIpUYCgbMG1/Pq3CMY/GUDam8/+BI3DMIzAUqWDbH8wvxI7cyXFj2fcibzDPjrHse1wc85F+wEsvZOa7h6237c+j7OQ4/mRc1vUwNKV+L+/6bmU9n3pJBYYiFRiKVGAoUoGhSAWGIhUYilRgKFKBoUgFhiIVGIpUYChSgaFIBYYiFRiKVNB5KBFxU0R8sOtxSGvpPBSaP2x5Yv+CiDg1Iv53R+ORjjLWUCLitvYv0q652grLloBDYxiSNJJxzyhzwLCrJ64USgIREfMRcdQYI2ImIoZduVHaNNP6mfmkifgxINvLmvZ4K7xZ4Ddo/l66NHbTEMpRM0NmPgO8f+QdNhdMuxZgJ8eOPjKpNQ0H8wHcEBF3RMTFEbFzpadb65GZt2fmnszcs9UuzaPpNNEZJSJ2Aye3X+8B7m9v+irwh+14HgcOR8TrNH8u+RDN067l8c4B833ffzwzp/nvEWobmEQon42I64HXaf4e37Pt1wvAsTQzyn/PzG+0679vAmOS1mXcoXwK+BuZuepLvau9ehUR99DMFi+Na3BS1VhD2eCfFfsww19aliZiWg7mV1u+OMmBSKuZhpeH4ci/3bdsHng0IhZpztT3aOJZPpC/NTNvndwQ9XY2DaH8qVzhkvqZubDaBu1xzTTMhnqb6DyUlSIpbrM0huFIK/K3slRgKFKBoUgFhiIVGIpUYChSgaFIBYYiFRiKVGAoUoGhSAWGIhV0/qbIcTvj3IN8+cuPdD2Mdfncyz/a9RBG8oVvX9T1ENbvL9RWc0aRCgxFKjAUqcBQpAJDkQoMRSowFKnAUKQCQ5EKDEUqMBSpwFCkAkORCgxFKjAUqcBQpAJDkQoMRSowFKnAUKQCQ5EKDEUqMBSpwFCkAkORCgxFKjAUqcBQpAJDkQoMRSowFKnAUKQCQ5EKDEUqMBSpwFCkAkORCgxFKjAUqcBQpAJDkQoMRSowFKnAUKQCQ5EK5roewLg9/toJXPo/r+h6GOvy7AsndD2E0fyfY7oewdg4o0gFhiIVGIpUYChSgaFIBYYiFRiKVGAoUoGhSAWGIhUYilRgKFKBoUgFhiIVGIpUYChSwVSEEhG/ERE/0/U4pNV0FkpE/LOI+NX2x1OBH17Htg9ExKVjGZi0grF+FDgiLgDem5n3tD//FPAjmXkXsMRboS4BvXadbwELwOH2thlgF7AnM59rl702znFLg8b9mflzgUuBe9qfTwcuA5ZDWdbr+/7szHzz54iYBb4PfK9vnf5tpbEbdyhLwKkRcTUQwCW8NVP0x5FvftMXSet84LuZeRipI+M+RlmiCWQnME/zlGqp77Zla0VwDW/NSFInxj2j9IAnM/NfA0TEDHBhe9sS8Hcj4q8B7wG+NrhxRJwEfAw4b/CmvnUiM3Ngu2uBawF2nPSOTfmH6O1t3DNKDPzcfwAfwD/OzLOA/7DK9p8DPp+Zz65w2+9ExFPAjYM3ZObtmbknM/fMH3/siEOX3jLuGWWOI2Oc77vPmb7vB4MiIj4LvBf46Ar7DeBjmfmNTRuptIZxh3IY+LMR8Uftzwn8p/b7oAln+fsZgIh4D81M8j7gZzNzccxjlIYaayiZ+dvAb69y8wxvhTIDzEXEacBe4N8DfyUzVztfctQMJI1Tl9ceHpxR5jLzyYg4OzOf73Bc0lE6CyUz/07fj29GU4zEGUUTNRVXs8/Mj69z/Q+PayzSSqbi3cPStDMUqcBQpAJDkQoMRSowFKnAUKQCQ5EKDEUqMBSpwFCkAkORCgxFKjAUqWAq3mY/TifveIUbTv3droexLnfsunD4SlPowUOndT2EsXFGkQoMRSowFKnAUKQCQ5EKDEUqMBSpwFCkAkORCgxFKjAUqcBQpAJDkQoMRSowFKnAUKQCQ5EKDEUqMBSpwFCkAkORCgxFKjAUqcBQpAJDkQoMRSowFKnAUKQCQ5EKDEUqMBSpwFCkAkORCgxFKjAUqcBQpAJDkQoMRSowFKnAUKQCQ5EKDEUqMBSpwFCkgrmuBzBur/Z28gc/OLPrYazLd77/zq6HMJJ8fbbrIYyNM4pUYChSgaFIBYYiFRiKVGAoUoGhSAWGIhUYilRgKFKBoUgFhiIVGIpUYChSgaFIBYYiFRiKVGAoUsGGQ4mI2YhYiIidEbGwGYMq3OcTEbG1Pt+rLa38mfmI2A+cBBwGDgGLQA8IYBY4HrgT+GTfNvcCF7brv9F+0a4/D+wA7svMa/q2mQUyM3sD9z+bmUvtjz3g9fK/UtqgciiZedZat0fEDTSx9PsI0Ot7gK+03eCsdhtweUS8QBNWD1ieqc7rW2/VfUqbbTOPUXYDr/QvyMzFzFyKiAcj4tLl5RFxZUR8vV2nd+Ru6AE3Z+Y5mbknMy/IzPMysz+S2OSxS2sa6cEWEadExPUDi08Gnlllk0c4cjY4DXh8lXV7NE/v1hwCzdM3aSJG/a18AnDdwLIzgUf7F7THGwB7gfP7bjob+Moq+15ieCgA90fE0ysd1EfEtRGxLyL2HXzpjZW2ldZl1AvgJX0P5ogImlD2D6x3Z0TsWV4/IvbRzAa7gYsj4lZgb2Ze3bdNJd4ALsnMp1YcXObtwO0Ap/zkiVn7J0mr28iVIvsPpmeAKzLzUP8KmXnVCPudGRxXROyiCfFc4C6aUCqzjrQpNhLKm9u2r2o90M4sc8DhzBz1N/k88OmIuBE4bvkugCeBx4C7aUJxptDEDA2lfer0EHAAeJXmYHsOOCYinqd56XahXTZD8yC+LCLuoDnXcojmnMcizSwUNDHMt9sstN9fnpnfBG4CbgEOAi9n5sEVxkS7H2kiKjPKw8COzFys7rSdWc7IzNcK684AO2lPRmbmc5W7wFA0QUNDac9zDJ7rGLZNAkMj6dv/UbPGEJ5s1ERtyT/7kJmndz0Gvb14dlsqMBSpwFCkAkORCgxFKjAUqcBQpAJDkQoMRSowFKnAUKQCQ5EKDEUqMBSpYEu+zX49FuIwf2LH/+t6GOvyzmPe2/UQRvLs/Lo+trSlOKNIBYYiFRiKVGAoUoGhSAWGIhUYilRgKFKBoUgFhiIVGIpUYChSgaFIBYYiFRiKVGAoUoGhSAWGIhUYilRgKFKBoUgFhiIVGIpUYChSgaFIBYYiFRiKVGAoUoGhSAWGIhUYilRgKFKBoUgFhiIVGIpUYChSgaFIBYYiFRiKVGAoUoGhSAWGIhUYilRgKFLBXNcDGLfDOcuLh3d1PYx1ObC40PUQRnM4uh7B2DijSAWGIhUYilRgKFKBoUgFhiIVGIpUYChSgaFIBYYiFRiKVGAoUoGhSAWGIhUYilRgKFKBoUgFhiIVbDiUiJiNiIWI2BkRE/kMa0Q8ERFnTuK+JFjHZ+YjYj9wEnAYOAQsAj0ggFngeOBO4JN929wLXNiu/0b7Rbv+PLADuC8zr+nbZhbIzOwN3P9sZi61P/aA18v/SmmDyqFk5llr3R4RN9DE0u8jQK/vAb7SdoOz2m3A5RHxAk1YPWB5pjqvb71V9yltts08RtkNvNK/IDMXM3MpIh6MiEuXl0fElRHx9Xad3pG7oQfcnJnnZOaezLwgM8/LzP5IYpPHLq1ppAdbRJwSEdcPLD4ZeGaVTR7hyNngNODxVdbt0Ty9W3MINE/fVhvftRGxLyL2HXjp0JBdScON+lv5BOC6gWVnAo/2L2iPNwD2Auf33XQ28JVV9r3E8FAA7o+Ip1c6qM/M29vZaM9xJ27Ra2Rpqox6Abyk78EcEUETyv6B9e6MiD3L60fEPprZYDdwcUTcCuzNzKv7tqnEG8AlmfnUiOOX1mUjV4rsP5ieAa7IzCOe52TmVSPsd2ZwXBGxiybEc4G7aEKpzDrSpthIKG9u276q9UA7s8wBhzMzR9zvPPDpiLgROG75LoAngceAu2lCGXX/0roNDaV96vQQcAB4leZgew44JiKep3npdqFdNkPzIL4sIu6gOddyiOacxyLNLBQ0Mcy32yy031+emd8EbgJuAQ4CL2fmwRXGRLsfaSIqM8rDwI7MXKzutJ1ZzsjM1wrrzgA7aU9GZuZzlbvAUDRBQ0Npz3MMnusYtk0CQyPp2/9Rs8YQnmzURG3JP/uQmad3PQa9vXh2WyowFKnAUKQCQ5EKDEUqMBSpwFCkAkORCgxFKjAUqcBQpAJDkQoMRSrYku8eXo+Z6HHs7BvDV5wi8zNb9FME2/jX7jb+p0mbx1CkAkORCgxFKjAUqcBQpAJDkQoMRSowFKnAUKQCQ5EKDEUqMBSpwFCkAkORCgxFKjAUqcBQpAJDkQoMRSowFKnAUKQCQ5EKDEUqMBSpwFCkAkORCgxFKjAUqcBQpAJDkQoMRSowFKnAUKQCQ5EKDEUqMBSpwFCkAkORCgxFKjAUqcBQpAJDkQoMRSowFKlgrusBjFsSLOZs18NYl8zoegijya4HMD7OKFKBoUgFhiIVGIpUYChSgaFIBYYiFRiKVGAoUoGhSAWGIhUYilRgKFKBoUgFhiIVGIpUYChSwYZDiYjZiFiIiJ0RsbAZgyrc5xMRceYk7kuCdXwUOCL2AycBh4FDwCLQAwKYBY4H7gQ+2bfNvcCF7fpvtF+0688DO4D7MvOavm1mgczM3sD9z2bmUvtjD3i9/K+UNqgcSmaetdbtEXEDTSz9PgL0+h7gK203OKvdBlweES/QhNUDlmeq8/rWW3Wf0mbbzGOU3cAr/QsyczEzlyLiwYi4dHl5RFwZEV9v1+kduRt6wM2ZeU5m7snMCzLzvMzsjyQ2eezSmkZ6sEXEKRFx/cDik4FnVtnkEY6cDU4DHl9l3R7N07s1h0Dz9E2aiFF/K58AXDew7Ezg0f4F7fEGwF7g/L6bzga+ssq+lxgeCsD9EfH0Sgf1EXFtROyLiH0HXjxU2JW0tlGv65X0PZgjImhC2T+w3p0RsWd5/YjYRzMb7AYujohbgb2ZeXXfNpV4A7gkM59acXCZtwO3A/zI2cdv46tNaVI2cgG8/oPpGeCKzDzi13dmXjXCfmcGxxURu2hCPBe4iyaUyqwjbYqNhPLmtu2rWg+0M8sccDgzR/1NPg98OiJuBI5bvgvgSeAx4G6aUJwpNDFDQ2mfOj0EHABepTnYngOOiYjnaV66XWiXzdA8iC+LiDtozrUcojnnsUgzCwVNDPPtNgvt95dn5jeBm4BbgIPAy5l5cIUx0e5HmojKjPIwsCMzF6s7bWeWMzLztcK6M8BO2pORmflc5S4wFE3Q0FDa8xyD5zqGbZPA0Ej69n/UrDGEJxs1UVvyavaZeXrXY9Dbi2e3pQJDkQoMRSowFKnAUKQCQ5EKDEUqMBSpwFCkAkORCgxFKjAUqcBQpAJDkQq25Nvs16O5rtHW+tRwxNYa75u28UfpnFGkAkORCgxFKjAUqcBQpAJDkQoMRSowFKnAUKQCQ5EKDEUqMBSpwFCkAkORCgxFKjAUqcBQpAJDkQoMRSowFKnAUKQCQ5EKDEUqMBSpwFCkAkORCgxFKjAUqcBQpAJDkQoMRSowFKnAUKQCQ5EKDEUqMBSpwFCkAkORCgxFKjAUqcBQpAJDkQoMRSowFKlgrusB6GiZ0fUQRpNdD2B8nFGkAkORCgxFKjAUqcBQpAJDkQoMRSowFKnAUKQCQ5EKDEUqMBSpwFCkAkORCgxFKjAUqcBQpAJDkQo2HEpEzEbEQkTsjIiFzRhU4T6fiIgzJ3FfEqzjM/MRsR84CTgMHAIWgR4QwCxwPHAn8Mm+be4FLmzXf6P9ol1/HtgB3JeZ1/RtMwtkZvYG7n82M5faH3vA6+V/pbRB5VAy86y1bo+IG2hi6fcRoNf3AF9pu8FZ7Tbg8oh4gSasHrA8U53Xt96q+5Q222Yeo+wGXulfkJmLmbkUEQ9GxKXLyyPiyoj4ertO78jd0ANuzsxzMnNPZl6QmedlZn8kscljl9Y00oMtIk6JiOsHFp8MPLPKJo9w5GxwGvD4Kuv2aJ7erTkEmqdvq43v2ojYFxH7Xn3x0JBdScON+lv5BOC6gWVnAo/2L2iPNwD2Auf33XQ28JVV9r3E8FAA7o+Ip1c6qM/M29vZaM+ud07k9QVtc6NeAC/pezBHRNCEsn9gvTsjYs/y+hGxj2Y22A1cHBG3Ansz8+q+bSrxBnBJZj414vilddnIlSL7D6ZngCsy84jnOZl51Qj7nRkcV0TsognxXOAumlAqs460KTYSypvbtq9qPdDOLHPA4cwc9QKb88CnI+JG4LjluwCeBB4D7qYJZRtfwFPTZmgo7VOnh4ADwKs0B9tzwDER8TzNS7cL7bIZmgfxZRFxB825lkM05zwWaWahoIlhvt1mof3+8sz8JnATcAtwEHg5Mw+uMCba/UgTUZlRHgZ2ZOZidaftzHJGZr5WWHcG2El7MjIzn6vcBYaiCRoaSnueY/Bcx7BtEhgaSd/+j5o1hvBkoyZqS/7Zh8w8vesx6O3Fs9tSgaFIBYYiFRiKVGAoUoGhSAWGIhUYilRgKFKBoUgFhiIVGIpUYChSgaFIBVvybfaaUtv4o3TOKFKBoUgFhiIVGIpUYChSgaFIBYYiFRiKVGAoUoGhSAWGIhUYilRgKFKBoUgFhiIVGIpUYChSgaFIBYYiFRiKVGAoUoGhSAWGIhUYilRgKFKBoUgFhiIVGIpUYChSgaFIBYYiFRiKVGAoUoGhSAWGIhUYilRgKFKBoUgFhiIVGIpUYChSgaFIBYYiFRiKVBCZ2fUYxioi/hj47ph2/0PAC2Pa97g45iO9LzPfPWylbR/KOEXEvszc0/U41sMxj8anXlKBoUgFhrIxt3c9gBE45hF4jCIVOKNIBYYiFRiKVGAoUoGhSAX/H4rpCfAo30JEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence = 'I feel hungry'\n",
    "# sentence = 'tensorflow is a framework for deep learning'\n",
    "\n",
    "translate(sentence, encoder, decoder, source2idx, target2idx, s_max_len, t_max_len)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "nmt_with_attention.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1C4fpM7_7IL8ZzF7Gc5abywqQjeQNS2-U",
     "timestamp": 1527858391290
    },
    {
     "file_id": "1pExo6aUuw0S6MISFWoinfJv0Ftm9V4qv",
     "timestamp": 1527776041613
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
